# AWS Notes

## IAM
- **Policies** : Pour Users et Groupes
- **Roles** : Pour Services

---
## EC2
### Option achat
- **On demand** : Arrive quand on veut √† l'h√¥tel, mais on paie plein tarif.
- **Reserved** : R√©serve √† l'avance pour une longue dur√©e et on obtient une r√©duction.
- **Savings Plans** : Paie un montant fixe par heure pendant une certaine dur√©e, peu importe le type de chambre.
- **Instances Spot** : Prends sur les chambres vides √† petit prix, l'h√¥tel peut nous demander de partir √† tout moment.
- **Dedicated host** : R√©serve tout un b√¢timent de l'h√¥tel.
- **Capacity reservations** : R√©serve une chambre √† plein tarif pour une dur√©e d√©termin√©e, m√™me si on ne l'utilise pas.

### Placement Group
- **Cluster** : Groupe d'instances dans une m√™me AZ pour faible latence.
- **Spread** : Instances r√©parties sur diff√©rents mat√©riels (max 7 par AZ).
- **Partition** : Instances r√©parties par partitions ind√©pendantes (jusqu'√† des centaines par AZ, id√©al pour Hadoop, Cassandra, Kafka).

---
## High availabity & Scalabilty
‚ö†Ô∏è GENEVE protocol port 6081 => Gateway Load Balancer

---
## CloudFront & AWS Global Accelerator

### CloudFront vs S3 Cross Region Replication

| Crit√®res               | CloudFront                           | S3 Cross-Region Replication   |
|------------------------|--------------------------------------|--------------------------------|
| **Fonction principale**| Acc√©l√©ration livraison contenu mondial| R√©plication r√©gionale S3       |
| **Latence utilisateurs**| Tr√®s faible ‚úÖ                       | R√©duite (mais plus √©lev√©e qu'un CDN) ‚ö†Ô∏è |
| **Stockage des donn√©es**| Cache temporaire (Edge Locations)    | Copie permanente des donn√©es ‚úÖ|
| **Disponibilit√©**      | Globale ‚úÖ                            | R√©gionale (multi-r√©gion) ‚úÖ    |
| **Co√ªt**               | Bas √† moyen (r√©duction transfert) ‚úÖ  | Plus √©lev√© (double stockage) ‚ö†Ô∏è |
| **Gestion complexit√©** | Simple ‚úÖ                             | Moyenne √† √©lev√©e ‚ö†Ô∏è            |


- Utilise **CloudFront** pour servir tr√®s rapidement du contenu √† des utilisateurs finaux partout dans le monde.
- Utilise **S3 Cross-Region Replication** pour la r√©silience, la disponibilit√© multi-r√©gion des donn√©es, ou des obligations l√©gales.

---
## Decoupling applications: SQS, SNS, Kinesis, Active MQ
### Amazon Kinesis Data Firehose VS Kinesis Data Streams


| **Crit√®re**                        | **Kinesis Data Streams**                      | **Kinesis Data Firehose**                            |
|-----------------------------------|----------------------------------------------|------------------------------------------------------|
| **Type de service**               | Data streaming (temps r√©el)                  | Ingestion & livraison automatis√©e (quasi temps r√©el)|
| **Niveau de gestion**             | Semi-g√©r√© : tu g√®res les shards & consommateurs | Full-managed (z√©ro infra √† g√©rer)                   |
| **Latence**                       | ~200 ms                                      | 1 √† 5 minutes environ                                |
| **Transformation des donn√©es**    | Personnalis√©e via app Lambda/EC2             | Int√©gr√©e via Lambda (facultatif)                    |
| **Stockage interm√©diaire**        | Donn√©es retenues 24h √† 7 jours (ou +)        | Pas de stockage r√©el (stream direct vers cible)     |
| **Destinations possibles**        | Traitement personnalis√©                      | S3, Redshift, OpenSearch, Splunk, Datadog‚Ä¶          |
| **Cas d‚Äôusage typique**           | Monitoring temps r√©el, custom analytics      | Livrer des logs ou donn√©es brutes vers S3/Redshift  |

### SQS vs SNS vs Kinesis

| **Crit√®re**                            | **Amazon SQS**                                                                 | **Amazon SNS**                                                           | **Amazon Kinesis (Data Streams)**                                              |
|----------------------------------------|--------------------------------------------------------------------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **Mod√®le d‚Äôarchitecture**              | File de messages (Queue)                                                      | Publication / abonnement (Pub/Sub)                                     | Streaming de donn√©es en temps r√©el                                            |
| **Mode de livraison**                  | Les consommateurs tirent les messages (**pull**)                              | SNS envoie activement les messages (**push**)                           | **Pull standard**, ou **Push** avec *Enhanced Fan-Out*                       |
| **Dur√©e de vie des messages**          | Supprim√©s apr√®s consommation                                                  | Non persist√©s (perdus s‚Äôils ne sont pas livr√©s)                         | Conservent les donn√©es **jusqu‚Äô√† X jours** (24h √† 365j)                       |
| **Ordonnancement**                     | Garanti uniquement avec **FIFO queues**                                       | Pas d‚Äôordonnancement                                                    | Ordre garanti **au niveau du shard**                                         |
| **Scalabilit√© des consommateurs**      | Autant de consommateurs que n√©cessaire                                        | Jusqu‚Äô√† **12,500,000** abonn√©s                                          | **1 MB/s en lecture / 2 MB/s en √©criture par shard**<br>Enhanced Fan-Out : 2 MB/s par consommateur |
| **D√©bit √† provisionner**               | ‚ùå Pas n√©cessaire                                                              | ‚ùå Pas n√©cessaire                                                        | ‚úÖ **Oui**, sauf en mode on-demand                                           |
| **Fan-out (envoi √† plusieurs cibles)** | N√©cessite SNS ou un traitement manuel                                         | Int√©gr√© nativement                                                      | Possible via Enhanced Fan-Out                                                |
| **Cas d‚Äôusage typique**                | D√©couplage applicatif, traitement asynchrone                                  | Notifications multiples, diffusion simple                               | Traitement de flux en temps r√©el, analytics, ETL                             |
| **Fonctionnalit√©s sp√©ciales**          | D√©lai par message, DLQ, FIFO                                                  | Jusqu‚Äô√† **100 000 sujets**                                              | Lecture en diff√©r√© (replay), traitement Big Data                             |

---
## Containers on AWS

### Comparatif : ECS vs EKS vs Fargate

| **Crit√®re**                         | **Amazon ECS**                             | **Amazon EKS**                             | **AWS Fargate**                                         |
|------------------------------------|--------------------------------------------|--------------------------------------------|---------------------------------------------------------|
| **Type de service**                | Orchestration de conteneurs AWS natif      | Orchestration de conteneurs via Kubernetes | Mode d'ex√©cution (backend) pour ECS ou EKS              |
| **Orchestration**                  | Propri√©taire AWS                           | Kubernetes (standard open-source)          | G√©r√© par AWS                                            |
| **Compatibilit√© outils K8s**       | ‚ùå Non                                      | ‚úÖ Oui (kubectl, Helm‚Ä¶)                    | ‚úÖ Oui, via ECS ou EKS                                  |
| **Plan de contr√¥le**               | G√©r√© par AWS                               | G√©r√© par AWS                               | Pas concern√©                                            |
| **Gestion des n≈ìuds (compute)**    | EC2 ou Fargate                              | EC2, Fargate ou self-managed EC2           | **Z√©ro gestion EC2** (serverless)                       |
| **Courbe d‚Äôapprentissage**         | üìâ Facile                                   | üìà Plus complexe (Kubernetes)              | üìâ Tr√®s simple                                          |
| **Flexibilit√© / Portabilit√©**      | ‚ùå Moins flexible, AWS-only                | ‚úÖ Tr√®s flexible, multi-cloud possible     | ‚ùå AWS only, moins de personnalisation                  |
| **Scalabilit√© automatique**        | Oui (avec service + ALB)                    | Oui (avec HPA, Karpenter ou Fargate)       | Oui (auto-scaling int√©gr√©)                             |
| **Cas d‚Äôusage typique**            | D√©ploiements simples, applications web      | Architectures microservices avanc√©es       | Conteneurs rapides, sans infra √† g√©rer                  |
| **Facturation**                    | EC2 ou Fargate                              | EC2 ou Fargate                              | √Ä la **seconde** (CPU + RAM utilis√©s)                  |

- **ECS** : simple, rapide, AWS-only, parfait pour d√©ployer des apps conteneuris√©es sans trop de complexit√©.
- **EKS** : puissance et standardisation Kubernetes, mais plus technique.
- **Fargate** : **mode d‚Äôex√©cution serverless** pour ECS ou EKS ‚Üí z√©ro infra √† g√©rer.

---
## Data & Analytics
### Amazon Athena 

**Amazon Athena**, c‚Äôest comme un **moteur de requ√™tes SQL** directement sur tes donn√©es stock√©es dans **S3**.  

- **Service serverless** : aucun cluster ou serveur √† g√©rer.
- **Repose sur Presto** (moteur SQL distribu√©), plus commun√©ment appel√© **Trino** aujourd‚Äôhui.
- **Int√©gration native S3** : tu peux **analyser** les donn√©es dans divers formats (CSV, JSON, ORC, Parquet, AVRO) stock√©s dans **n‚Äôimporte quel bucket**.
- **Facturation** : bas√©e sur le **volume de donn√©es scann√©es** (optimise donc en compressant / partitionnant / convertissant en Parquet).
- **Partage de m√©tadonn√©es** : utilise le **Glue Data Catalog** (ou un Hive Metastore) pour stocker la structure des tables (sch√©ma).
- **Performance** : meilleure si tes donn√©es sont **partitionn√©es** (par date, par cat√©gorie) et dans un **format colonne** (ex. Parquet).

- **Cas d‚Äôusage** : 
	- Analyses ad hoc de logs (CloudTrail, ELB logs, etc.) directement dans S3.  
	- **Data lake** : extraire/combiner des donn√©es sans ETL lourd.  
	- Reporting ponctuel, exploration rapide des donn√©es.

### Redshift

**Amazon Redshift**, c‚Äôest un **data warehouse** (entrep√¥t de donn√©es) manag√©.  
Contrairement √† une base transactionnelle (genre RDS), Redshift est **optimis√© pour le traitement analytique** de **grandes quantit√©s de donn√©es** (g√©n√©ralement historiques), o√π tu vas faire des **requ√™tes complexes** (agr√©gations, jointures lourdes).  
Il stocke les donn√©es **en colonnes** plut√¥t qu‚Äôen lignes, ce qui facilite les **analyses massives** et r√©duit l‚Äôespace disque.

> En clair, **Redshift** te permet de **faire du BI, des dashboards** et des **rapports** sur de gros volumes de donn√©es, avec des **performances nettement sup√©rieures** √† une base SQL classique pour la partie analytique.

- **Stockage en colonnes** : id√©al pour les requ√™tes OLAP (analyses).
- **Clusters** : un n≈ìud leader + n≈ìuds compute qui parall√©lisent les requ√™tes.
- **Types de n≈ìuds** :  
  - **RA3** (scalable, stockage sur S3 avec caching local),  
  - **DC2** (SSD local),  
  - **DS2** (HDD local) (plus ancien).
- **S√©curit√©** : VPC, chiffrement KMS, IAM, etc.
- **Int√©gration S3** : via **Redshift Spectrum**, tu peux requ√™ter directement des donn√©es dans S3 **sans les charger** dans Redshift.
- **Concurrence** : supporte de multiples utilisateurs ex√©cutant des requ√™tes simultan√©ment.
- **Maintenance & backups** : automatis√©es par AWS, snapshots, point-in-time restore.

- **Cas d‚Äôusage** :
	- **Entreposage de donn√©es** (Data Warehouse) pour analyses BI (Business Intelligence).
	- Grandes tables pour calculer des agr√©gats, effectuer des jointures lourdes.
	- G√©n√©ration de rapports, dashboards (avec QuickSight, Tableau, Power BI‚Ä¶).

### Opensearch

Voici une pr√©sentation **en deux parties** d‚Äô**Amazon OpenSearch Service** (anciennement **Amazon Elasticsearch Service**), avec un lien vers l‚Äôexamen **AWS SAA** :


**Amazon OpenSearch Service**, c‚Äôest comme un **moteur de recherche** manag√© qui te permet de faire des **recherches ultra-rapides** sur de gros volumes de donn√©es textuelles ou semi-structur√©es.  
Tu peux y stocker des logs, des documents (JSON), et ex√©cuter des **requ√™tes de recherche** ou **d‚Äôanalytique** (agr√©gations) en **temps quasi r√©el**.  
C‚Äôest super pour les **dashboards** de monitoring, la recherche libre-texte, ou l‚Äôanalyse de logs.

> En clair, **OpenSearch** est √† la fois une **base orient√©e recherche** et un **moteur d‚Äôanalyse** pour gros volumes de donn√©es, sans config manuelle d‚ÄôElasticsearch.

- **Compatible avec les APIs Elasticsearch / OpenSearch** ‚Üí tu peux utiliser les **outils Kibana / OpenSearch Dashboards** pour visualiser tes donn√©es.
- **Gestion manag√©e** : pas besoin d‚Äôinstaller ou de patcher Elasticsearch, AWS s‚Äôen charge.  
- **Scalabilit√©** : tu peux choisir le nombre de n≈ìuds, leur type (g√©n√©ral / RAM / storage-optimized), la taille du cluster, et configurer l‚Äôauto-scaling (certaines limites).
- **S√©curit√©** : Int√©gration IAM, politiques de contr√¥le d‚Äôacc√®s, VPC, chiffrement (KMS), etc.
- **Domaines** : tu cr√©es un ‚Äúdomaine‚Äù OpenSearch qui contient tes index (collections de documents).
- **Use cases** :  
  - Recherche de texte en **plein texte** (web, e-commerce)  
  - **Analyse de logs** (avec ingestion via Kinesis Firehose, Logstash, ou Beats)  
  - Monitoring de performances (m√©triques, dashboards)  
  - Visualisations interactives (Kibana / OpenSearch Dashboards)


- **Cas d‚Äôusage typique** :
	- **Recherche** (catalogues, sites web, documents textuels)
	- **Analytics en temps r√©el** sur des **logs** (observabilit√©, SIEM)
	- **Dashboarding** (Kibana / OpenSearch Dashboards)

### EMR

**Amazon EMR**, c‚Äôest un service **manag√©** qui te permet de d√©ployer facilement des **clusters Big Data** bas√©s sur des **outils open-source** comme Hadoop, Spark, Hive, Presto, etc.  
Au lieu d‚Äôinstaller et de configurer toi-m√™me un **cluster Hadoop** (avec toute sa complexit√©), AWS le fait pour toi ; tu as juste √† choisir la taille du cluster (nombre de n≈ìuds EC2) et le logiciel que tu veux utiliser.

> **En clair**, tu peux **analyser de gigantesques volumes de donn√©es** ou **ex√©cuter des jobs big data** (batch, analytics) sans g√©rer toute l‚Äôinfrastructure.  


### ‚öôÔ∏è **Amazon EMR (Elastic MapReduce)** :
- **Bas√© sur EC2** : tu as un **cluster** (master + core + task nodes) g√©r√© par EMR.
- **Int√©gration** :  
  - **S3** (stockage principal des donn√©es)  
  - **EMRFS** (interface S3 compatible HDFS)  
  - **AWS Glue Data Catalog** pour la d√©couverte de sch√©mas  
  - **CloudWatch** pour logs et monitoring
- **Logiciels pris en charge** : Hadoop, Spark, Hive, Presto, HBase, Pig, etc.
- **Tarification** : au temps de fonctionnement du cluster et selon la taille des instances.
- **Architecture** : cluster ephemeral (tu le lances pour un job, puis tu l‚Äôarr√™tes) ou permanent (toujours actif).
- **S√©curit√©** : IAM (r√¥les), chiffrement KMS, isolation VPC, etc.

- **Cas d‚Äôusage** :
	- Analyses de gros volumes (multi-To / Po) en batch (ETL, machine learning Spark, etc.).
	- Traitement Hadoop/Spark pour g√©n√©rer des donn√©es agr√©g√©es, transformer des datasets avant de les stocker en data warehouse (Redshift) ou en data lake (S3).

### Quicksight
Amazon QuickSight est un service **BI (Business Intelligence) enti√®rement manag√©** qui permet de cr√©er rapidement des **tableaux de bord interactifs** et des **visualisations de donn√©es**. Il est **serverless**, ne n√©cessite pas d'infrastructure √† g√©rer, et s‚Äôint√®gre avec de nombreuses sources de donn√©es (S3, RDS, Redshift, Athena, DynamoDB, etc.). Voici ses points essentiels :

- **Principales caract√©ristiques** :
	  - **Analyses interactives et tableaux de bord** : permet de concevoir des graphiques et rapports dynamiques, directement partageables avec les utilisateurs.  
	  - **Pay-per-session** : facturation flexible selon le nombre de sessions (ou licences mensuelles selon l‚Äôoffre).  
	  - **ML Insights** : fonctionnalit√©s d'analyse augment√©e (d√©tection d‚Äôanomalies, pr√©visions automatis√©es).  
	  - **S√©curit√© et gestion des acc√®s** : int√©gration IAM, chiffrement, row-level security pour filtrer la donn√©e au niveau utilisateur.  
	  - **Mode SPICE** : moteur in-memory pour acc√©l√©rer les analyses et r√©duire les co√ªts des requ√™tes directes.

- **Cas d‚Äôusage** :  
	  - **Rapports et tableaux de bord pour la direction** : visualisation rapide des KPI (ventes, trafic, co√ªts).  
	  - **Analyses ad hoc** : exploration ponctuelle de donn√©es S3, Redshift, RDS, etc.  
	  - **Self-service BI** : chaque √©quipe peut cr√©er ses propres visualisations.  
	  - **Partage rapide** : publication de dashboards √† de nombreux utilisateurs, avec ou sans compte AWS.
- **Pour l‚Äôexamen AWS SAA** :
	- Peut appara√Ætre dans les questions li√©es √† l‚Äôanalytique ou au reporting.
	- Diff√©renciation par rapport √† d‚Äôautres services analytiques (Athena, Redshift, EMR) : QuickSight est purement visualisation / dashboard, pas un moteur de calcul Big Data.

### AWS Glue
AWS Glue est un service d‚Äôint√©gration de donn√©es enti√®rement manag√© qui facilite la d√©couverte automatique des sch√©mas, la pr√©paration et la transformation des donn√©es. Il est souvent utilis√© pour construire et g√©rer des pipelines de donn√©es vers des data lakes et des data warehouses (ex : Redshift). Il repose notamment sur des jobs ETL (Spark Python / Scala) et un catalogue central (AWS Glue Data Catalog) pour documenter les m√©tadonn√©es.

- **Principales caract√©ristiques** :  
  - **Data Catalog** : cr√©e automatiquement une structure (base de donn√©es, tables) en scannant S3 et d‚Äôautres sources.  
  - **ETL manag√© (Spark)** : ex√©cute des jobs de transformation (Python ou Scala), sans g√©rer de cluster.  
  - **Crawler automatique** : d√©tecte les sch√©mas et formate les m√©tadonn√©es dans le Glue Data Catalog.  
  - **Triggers et Workflows** : orchestre des t√¢ches ETL, planifi√©es ou d√©clench√©es par un √©v√©nement.  
  - **Int√©gration √©troite** : fonctionne avec S3, Redshift, RDS, DynamoDB, Athena, EMR, etc.  

- **Cas d‚Äôusage** :  
  - **Migration et nettoyage de donn√©es** : extraire, transformer et charger en data warehouse (ex : Redshift).  
  - **Data lake** : inventaire des tables (schemas) dans S3, recherche de donn√©es via Glue Data Catalog.  
  - **ETL serverless** : pas besoin de cr√©er un cluster Spark manuel.  
  - **Orchestration** : automatisation de pipelines Big Data (ingestion ‚Üí transformation ‚Üí chargement).  
- **Pour l‚Äôexamen AWS SAA** :
	- Peut appara√Ætre dans les questions d‚Äôarchitecture Big Data.
	- Se compare √† EMR + scripts custom ou √† Lambda pour des transformations simples. Glue est pratique pour du ETL manag√© et le catalogage de donn√©es.

### AWS Lake Formation
AWS Lake Formation est un service con√ßu pour automatiser la cr√©ation et la s√©curisation d‚Äôun data lake sur AWS. Il simplifie l‚Äôingestion, le catalogage et la configuration de politiques de s√©curit√© centralis√©es pour toutes les donn√©es stock√©es (souvent dans S3). Il s‚Äôappuie sur le Glue Data Catalog et offre des fonctionnalit√©s avanc√©es pour contr√¥ler l‚Äôacc√®s aux donn√©es (niveau table, colonne, voire cellule).

- **Principales caract√©ristiques** :  
	  - Simplifie et acc√©l√®re la mise en place d‚Äôun data lake dans S3 (importation, nettoyage, catalogage des donn√©es).  
	  - G√®re la **s√©curit√© et les acc√®s** via un mod√®le de contr√¥le fin (table, colonne).  
	  - Automatisation des pipelines d‚Äôingestion et de transformation (int√©gration avec Glue, EMR, Redshift, Athena).  
	  - Fait office de ‚Äúcouche de gouvernance‚Äù centralis√©e pour d√©finir qui peut acc√©der √† quelles donn√©es.  

- **Cas d‚Äôusage **:  
	  - **Centraliser les donn√©es** : consolider dans S3 diff√©rentes sources (RDS, NoSQL, fichiers on-premise‚Ä¶).  
	  - **S√©curiser fortement** : d√©finir des r√®gles d‚Äôacc√®s granulaires (RGPD, HIPAA).  
	  - **Partage de datasets** : permettre √† plusieurs √©quipes de consommer les m√™mes donn√©es, avec des autorisations adapt√©es.  

- **Pour l‚Äôexamen AWS SAA** :  
	  - Peut appara√Ætre dans les questions relatives √† la mise en place d‚Äôun **data lake** s√©curis√©, le catalogage et la gouvernance des donn√©es.  
	  - Se compare √† la solution classique ‚ÄúGlue + IAM Policies + Bucket Policies‚Äù : Lake Formation va plus loin en offrant une gouvernance plus fine et centralis√©e.  

---

